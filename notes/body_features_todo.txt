Play around with undersampling a bit to see if we can get unaligned videos aligned
	in many cases undersample generates an extra frame near the end. also in 
	three cases we at least 3 frames more than annotations; i think this 
	this is because annotations sometimes don't go until the end of video.
	We can solve both problems by cutting off some final frames!

Get raw body features processed for all views
Write big script that processes them and outputs json files for each video
Each json file can be like {A:{timeid:normalized_body...},B:{timeid:normalized_body,...}}

To do this we need:
Find way of figuring out who's A, B
Find way of associating bodies from different timesteps to one another (MSE?)

To verify it, we'll have to write a script that compares the number of body keypoints for A/B to the number of annotations we have (adjusted for the framesize)
